{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r\"d:\\Downloads\\Churn_Modelling.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:, 3:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "geography=pd.get_dummies(X[\"Geography\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      France  Germany  Spain\n",
       "0       True    False  False\n",
       "1      False    False   True\n",
       "2       True    False  False\n",
       "3       True    False  False\n",
       "4      False    False   True\n",
       "...      ...      ...    ...\n",
       "9995    True    False  False\n",
       "9996    True    False  False\n",
       "9997    True    False  False\n",
       "9998   False     True  False\n",
       "9999    True    False  False\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Germany  Spain\n",
       "0       False  False\n",
       "1       False   True\n",
       "2       False  False\n",
       "3       False  False\n",
       "4       False   True\n",
       "...       ...    ...\n",
       "9995    False  False\n",
       "9996    False  False\n",
       "9997    False  False\n",
       "9998     True  False\n",
       "9999    False  False\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender=pd.get_dummies(X[\"Gender\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Male\n",
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "...     ...\n",
       "9995   True\n",
       "9996   True\n",
       "9997  False\n",
       "9998   True\n",
       "9999  False\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([X,geography,gender],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['Geography','Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Germany  Spain   Male  \n",
       "0                  1        101348.88    False  False  False  \n",
       "1                  1        112542.58    False   True  False  \n",
       "2                  0        113931.57    False  False  False  \n",
       "3                  0         93826.63    False  False  False  \n",
       "4                  1         79084.10    False   True  False  \n",
       "...              ...              ...      ...    ...    ...  \n",
       "9995               0         96270.64    False  False   True  \n",
       "9996               1        101699.77    False  False   True  \n",
       "9997               1         42085.58    False  False  False  \n",
       "9998               0         92888.52     True  False   True  \n",
       "9999               0         38190.78    False  False  False  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state= 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shivram\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, Y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(X_train, Y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy: 0.808\n",
      "random forest accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "lr_accuracy = accuracy_score(Y_test, y_pred_lr)\n",
    "print(\"logistic regression accuracy:\",lr_accuracy)\n",
    "rf_accuracy=accuracy_score(y_pred_rf,Y_test)\n",
    "print(\"random forest accuracy:\",rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, Y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(X_train, Y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression\n",
      "            Feature  Coefficient\n",
      "1               Age     0.751746\n",
      "8           Germany     0.355364\n",
      "3           Balance     0.154088\n",
      "9             Spain     0.047838\n",
      "7   EstimatedSalary     0.029165\n",
      "5         HasCrCard    -0.023623\n",
      "0       CreditScore    -0.072306\n",
      "2            Tenure    -0.081290\n",
      "4     NumOfProducts    -0.084300\n",
      "10             Male    -0.269198\n",
      "6    IsActiveMember    -0.518268\n",
      "\n",
      " random forest\n",
      "\n",
      "             Feature  Importance\n",
      "1               Age    0.238901\n",
      "7   EstimatedSalary    0.148789\n",
      "3           Balance    0.143677\n",
      "0       CreditScore    0.141997\n",
      "4     NumOfProducts    0.131161\n",
      "2            Tenure    0.080119\n",
      "6    IsActiveMember    0.036838\n",
      "8           Germany    0.026714\n",
      "10             Male    0.018865\n",
      "5         HasCrCard    0.018585\n",
      "9             Spain    0.014354\n"
     ]
    }
   ],
   "source": [
    "print(\"logistic regression\")\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "print(coeff_df)\n",
    "print(\"\\n random forest\")\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\n\",rf_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, PReLU, ELU, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shivram\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'he_normal', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 20, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5048 - loss: 1.5264 - val_accuracy: 0.7940 - val_loss: 0.5739\n",
      "Epoch 2/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6645 - loss: 0.8510 - val_accuracy: 0.7955 - val_loss: 0.5384\n",
      "Epoch 3/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.7187 - val_accuracy: 0.7955 - val_loss: 0.5273\n",
      "Epoch 4/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.6394 - val_accuracy: 0.7955 - val_loss: 0.5187\n",
      "Epoch 5/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7625 - loss: 0.6062 - val_accuracy: 0.7955 - val_loss: 0.5124\n",
      "Epoch 6/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.5783 - val_accuracy: 0.7955 - val_loss: 0.5080\n",
      "Epoch 7/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.5609 - val_accuracy: 0.7955 - val_loss: 0.5062\n",
      "Epoch 8/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.5427 - val_accuracy: 0.7955 - val_loss: 0.5051\n",
      "Epoch 9/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.5391 - val_accuracy: 0.7955 - val_loss: 0.5041\n",
      "Epoch 10/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.5237 - val_accuracy: 0.7955 - val_loss: 0.5031\n",
      "Epoch 11/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7899 - loss: 0.5184 - val_accuracy: 0.7955 - val_loss: 0.5017\n",
      "Epoch 12/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.5175 - val_accuracy: 0.7955 - val_loss: 0.5014\n",
      "Epoch 13/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.5136 - val_accuracy: 0.7955 - val_loss: 0.5006\n",
      "Epoch 14/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.5131 - val_accuracy: 0.7955 - val_loss: 0.5000\n",
      "Epoch 15/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.5115 - val_accuracy: 0.7955 - val_loss: 0.4993\n",
      "Epoch 16/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.5097 - val_accuracy: 0.7955 - val_loss: 0.4985\n",
      "Epoch 17/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.5076 - val_accuracy: 0.7955 - val_loss: 0.4977\n",
      "Epoch 18/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5036 - val_accuracy: 0.7955 - val_loss: 0.4968\n",
      "Epoch 19/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.5048 - val_accuracy: 0.7955 - val_loss: 0.4960\n",
      "Epoch 20/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.5007 - val_accuracy: 0.7955 - val_loss: 0.4955\n",
      "Epoch 21/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.4984 - val_accuracy: 0.7955 - val_loss: 0.4940\n",
      "Epoch 22/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.5024 - val_accuracy: 0.7955 - val_loss: 0.4938\n",
      "Epoch 23/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4965 - val_accuracy: 0.7955 - val_loss: 0.4925\n",
      "Epoch 24/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4917 - val_accuracy: 0.7955 - val_loss: 0.4906\n",
      "Epoch 25/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4967 - val_accuracy: 0.7955 - val_loss: 0.4898\n",
      "Epoch 26/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4928 - val_accuracy: 0.7955 - val_loss: 0.4887\n",
      "Epoch 27/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4901 - val_accuracy: 0.7955 - val_loss: 0.4867\n",
      "Epoch 28/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.4894 - val_accuracy: 0.7955 - val_loss: 0.4849\n",
      "Epoch 29/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.4855 - val_accuracy: 0.7955 - val_loss: 0.4827\n",
      "Epoch 30/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.4883 - val_accuracy: 0.7955 - val_loss: 0.4812\n",
      "Epoch 31/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4873 - val_accuracy: 0.7955 - val_loss: 0.4805\n",
      "Epoch 32/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.4890 - val_accuracy: 0.7955 - val_loss: 0.4795\n",
      "Epoch 33/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.4846 - val_accuracy: 0.7955 - val_loss: 0.4780\n",
      "Epoch 34/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4849 - val_accuracy: 0.7955 - val_loss: 0.4772\n",
      "Epoch 35/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4809 - val_accuracy: 0.7955 - val_loss: 0.4760\n",
      "Epoch 36/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.4809 - val_accuracy: 0.7955 - val_loss: 0.4750\n",
      "Epoch 37/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.4821 - val_accuracy: 0.7955 - val_loss: 0.4745\n",
      "Epoch 38/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4767 - val_accuracy: 0.7955 - val_loss: 0.4723\n",
      "Epoch 39/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.4798 - val_accuracy: 0.7955 - val_loss: 0.4720\n",
      "Epoch 40/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4765 - val_accuracy: 0.7955 - val_loss: 0.4703\n",
      "Epoch 41/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.4772 - val_accuracy: 0.7955 - val_loss: 0.4691\n",
      "Epoch 42/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4756 - val_accuracy: 0.7955 - val_loss: 0.4681\n",
      "Epoch 43/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.4799 - val_accuracy: 0.7955 - val_loss: 0.4682\n",
      "Epoch 44/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4737 - val_accuracy: 0.7955 - val_loss: 0.4673\n",
      "Epoch 45/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.4740 - val_accuracy: 0.7955 - val_loss: 0.4666\n",
      "Epoch 46/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7959 - loss: 0.4831 - val_accuracy: 0.7955 - val_loss: 0.4677\n",
      "Epoch 47/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4758 - val_accuracy: 0.7955 - val_loss: 0.4657\n",
      "Epoch 48/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4726 - val_accuracy: 0.7955 - val_loss: 0.4640\n",
      "Epoch 49/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.4729 - val_accuracy: 0.7955 - val_loss: 0.4638\n",
      "Epoch 50/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.4800 - val_accuracy: 0.7955 - val_loss: 0.4649\n",
      "Epoch 51/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.4717 - val_accuracy: 0.7955 - val_loss: 0.4637\n",
      "Epoch 52/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.4792 - val_accuracy: 0.7955 - val_loss: 0.4643\n",
      "Epoch 53/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4710 - val_accuracy: 0.7955 - val_loss: 0.4627\n",
      "Epoch 54/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4647 - val_accuracy: 0.7955 - val_loss: 0.4614\n",
      "Epoch 55/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.4706 - val_accuracy: 0.7955 - val_loss: 0.4612\n",
      "Epoch 56/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.4697 - val_accuracy: 0.7955 - val_loss: 0.4609\n",
      "Epoch 57/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4678 - val_accuracy: 0.7955 - val_loss: 0.4595\n",
      "Epoch 58/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4661 - val_accuracy: 0.7955 - val_loss: 0.4598\n",
      "Epoch 59/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4710 - val_accuracy: 0.7955 - val_loss: 0.4599\n",
      "Epoch 60/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4677 - val_accuracy: 0.7955 - val_loss: 0.4585\n",
      "Epoch 61/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.4675 - val_accuracy: 0.7955 - val_loss: 0.4583\n",
      "Epoch 62/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.4700 - val_accuracy: 0.7955 - val_loss: 0.4578\n",
      "Epoch 63/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.4744 - val_accuracy: 0.7955 - val_loss: 0.4586\n",
      "Epoch 64/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8016 - loss: 0.4666 - val_accuracy: 0.7955 - val_loss: 0.4581\n",
      "Epoch 65/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4607 - val_accuracy: 0.7955 - val_loss: 0.4566\n",
      "Epoch 66/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4588 - val_accuracy: 0.7955 - val_loss: 0.4549\n",
      "Epoch 67/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.4689 - val_accuracy: 0.7955 - val_loss: 0.4557\n",
      "Epoch 68/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4688 - val_accuracy: 0.7955 - val_loss: 0.4563\n",
      "Epoch 69/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4617 - val_accuracy: 0.7955 - val_loss: 0.4556\n",
      "Epoch 70/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4689 - val_accuracy: 0.7955 - val_loss: 0.4559\n",
      "Epoch 71/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4600 - val_accuracy: 0.7955 - val_loss: 0.4543\n",
      "Epoch 72/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4619 - val_accuracy: 0.7955 - val_loss: 0.4536\n",
      "Epoch 73/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.4586 - val_accuracy: 0.7955 - val_loss: 0.4526\n",
      "Epoch 74/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.4658 - val_accuracy: 0.7955 - val_loss: 0.4535\n",
      "Epoch 75/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4577 - val_accuracy: 0.7955 - val_loss: 0.4520\n",
      "Epoch 76/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4607 - val_accuracy: 0.7959 - val_loss: 0.4515\n",
      "Epoch 77/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4623 - val_accuracy: 0.7959 - val_loss: 0.4522\n",
      "Epoch 78/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.4569 - val_accuracy: 0.7959 - val_loss: 0.4516\n",
      "Epoch 79/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4592 - val_accuracy: 0.7959 - val_loss: 0.4516\n",
      "Epoch 80/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4574 - val_accuracy: 0.7959 - val_loss: 0.4507\n",
      "Epoch 81/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4574 - val_accuracy: 0.7959 - val_loss: 0.4512\n",
      "Epoch 82/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.4613 - val_accuracy: 0.7959 - val_loss: 0.4512\n",
      "Epoch 83/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4604 - val_accuracy: 0.7959 - val_loss: 0.4517\n",
      "Epoch 84/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.4556 - val_accuracy: 0.7959 - val_loss: 0.4505\n",
      "Epoch 85/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4590 - val_accuracy: 0.7959 - val_loss: 0.4508\n",
      "Epoch 86/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4580 - val_accuracy: 0.7959 - val_loss: 0.4500\n",
      "Epoch 87/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.4543 - val_accuracy: 0.7959 - val_loss: 0.4493\n",
      "Epoch 88/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.4572 - val_accuracy: 0.7959 - val_loss: 0.4493\n",
      "Epoch 89/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.4585 - val_accuracy: 0.7959 - val_loss: 0.4495\n",
      "Epoch 90/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4542 - val_accuracy: 0.7959 - val_loss: 0.4481\n",
      "Epoch 91/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4575 - val_accuracy: 0.7959 - val_loss: 0.4484\n",
      "Epoch 92/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.4586 - val_accuracy: 0.7959 - val_loss: 0.4489\n",
      "Epoch 93/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.4614 - val_accuracy: 0.7959 - val_loss: 0.4498\n",
      "Epoch 94/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4604 - val_accuracy: 0.7959 - val_loss: 0.4495\n",
      "Epoch 95/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4583 - val_accuracy: 0.7959 - val_loss: 0.4492\n",
      "Epoch 96/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4574 - val_accuracy: 0.7959 - val_loss: 0.4474\n",
      "Epoch 97/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.4504 - val_accuracy: 0.7959 - val_loss: 0.4452\n",
      "Epoch 98/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.4594 - val_accuracy: 0.7952 - val_loss: 0.4445\n",
      "Epoch 99/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4565 - val_accuracy: 0.7952 - val_loss: 0.4445\n",
      "Epoch 100/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4567 - val_accuracy: 0.7952 - val_loss: 0.4453\n"
     ]
    }
   ],
   "source": [
    "model_history = classifier.fit(X_train, Y_train, validation_split=0.33, batch_size=10, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "classifier.save('churnmodel_ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "classifier=load_model('churnmodel_ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "nn accuracy:\n",
      "0.8053741455078125\n",
      "Confusion Matrix - neural network:\n",
      "[[1545   50]\n",
      " [ 288  117]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm_lr = confusion_matrix(Y_test, y_pred_lr)\n",
    "cm_rf = confusion_matrix(Y_test, y_pred_rf)\n",
    "y_prob = classifier.predict(X_test)\n",
    "y_pred = (y_prob > 0.3).astype(int)\n",
    "print(\"nn accuracy:\")\n",
    "print(model_history.history['accuracy'][-1])\n",
    "print(\"Confusion Matrix - neural network:\")\n",
    "cm_nn = confusion_matrix(Y_test, y_pred)\n",
    "print(cm_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABv4AAAHqCAYAAADMEzkrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXpFJREFUeJzt3Qd4VFX6B+CPLqAgoCgWmmIHRVTs2HvXddd1LWsvqOha10XFgoqK2BV7772sBXTtvWBHsRcQUUEFlTb/51z/iQkEJTFhkpv3fZ6RzJ2bO2cGnPxyv3O/06BQKBQCAAAAAAAAqNMaFnsAAAAAAAAAwJ+n8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwB/wp66yzTnarLp07d47dd9+92o5HRIMGDeKEE04o9jAAgCJJ2SplLAAAAPJP4Q9y4qqrrsoKPC+99FLUds8880xWiBo/fnyNPk86wZXek5Jby5YtY5VVVolrrrmmRp8XAKjfeazk1rhx41h44YWzwtsXX3xR7OHV2vep7O3oo4+O2mjgwIFx1113FXsYAEAtduGFF2Z5pnfv3hU+XpJ3zjrrrNk6r5fOnaVtCyywQEyaNKnC815bbLFFNb8KIA8aF3sAQN328MMPV6nwN2DAgOwk2LzzzlvusZEjR0bDhtU3J2GFFVaIf/3rX9nXo0ePjssuuyx22223+OWXX2LvvfeO+uCnn37KTjwCAHPGiSeeGF26dImff/45nnvuuexEzlNPPRVvvvlmzDXXXMUeXq17n8pabrnlorYW/nbYYYfYZpttij0UAKCWuv7667Ni3AsvvBCjRo2KxRdfvML9zjjjjNh///2jRYsWs3XcsWPHxkUXXVR6fgvgjzgTDPwpTZs2rdbjNWvWrFqPl2bZ/+Mf/yi9n4qNXbt2jbPPPnuOF/4mTpyYXXU4pznBCABz1qabbhorrbRS9vVee+0V8803X5x++ulxzz33xI477ljs4dXK9ykPmQsAqL8++uijbKL7HXfcEfvuu29WBDz++OMrnKD+2muvxcUXXxyHHXbYbB07fU8qFh5wwAHRvHnzGhg9kDdafUI98+qrr2YnWVq1ahVzzz13rL/++tlM9Bm9/vrr0adPnyxQLLLIInHyySfHlVdembUY+Pjjj393jb/zzjsvll122WzmUps2bbITOjfccENpm4Ijjjgi+zrN8C5pc1ByzIrW+EstQQ899NDssVQYTOPZddddY9y4cZV+/fPPP38stdRS8cEHH5TbPn369BgyZEg27lQoS20UUlD77rvvZtovvYaFFlooe33rrrtuvP322zONu6RFw+OPP54Fs/bt22fjLvHf//431lprreyk1DzzzBObb755vPXWW+Wea8yYMfHPf/4z+770ujt06BBbb711ufc/tYDYeOONsxOK6e8qvad77LHHH67xNzv/Dkpew9NPP52F0fTepfFuu+228fXXX1f6vQeA+ir9zE/K5o/JkyfHcccdF7169YrWrVtnP2PTfo899li5700/99PP4zPPPDOGDh0aiy22WJYLVl555XjxxRdneq7UjjJdNZfyTPrzzjvvnGVxLM0aX3TRRbPjLbnkktlzFAqFcvul5+7bt2/ceuutscwyy2R5Y7XVVos33ngje/ySSy7JZrOn50uZsGxO+bMeffTR0ryUukSkHPTOO++U26ekBVbKY3//+9+z7LnmmmuWPn7ddddl73Ead9u2beNvf/tbfPbZZ+WO8f7778f2228fCy64YPY6UvZK+02YMKH0PUjv19VXX12aXa1JDQCUlQp9KYek8zupS0C6X5E11lgj1ltvvRg0aFDWoWl2pMz41VdfZVf9AcwOV/xBPZIKS+nkSSr2HHnkkdGkSZPsZE06SZMKVCU9yNMaNKmglU5qHHPMMdnJltQic3auxrv00kvj4IMPzkLOIYcckrW4SkXE559/PjsZs91228V7770XN954Y3bVXSpYJamoVJEff/wxG3M6yZMKWiuuuGJW8Esz5j///PPS759dU6dOzb4vhbGyUpEvFbpSoS2NP83UOv/887MCWSp8pfcqSe9HCmdbbrllVnAbMWJE9md6nRVJRb/02lJISyeMkmuvvTZrN5q+L83+T33aU3hLJ6nS86UiYpJOQKW/s4MOOijbllo7PPLII/Hpp5+W3t9oo42y46f1cNIJsXSyLc0uq45/ByXS86f3K81US8dPBdJ0AvDmm2+u1HsPAPVVSTGsbP74/vvvs3y10047ZV0Ifvjhh7j88suzfJDaQ6WZ3WWlSVRpn5RZUkZLeSTlqg8//LA0p6QW7Ck/pALdqaeeGt98803pJKKyUnFvq622yoqMe+65Z/ZcDz30UDY5K+XAlNHKevLJJ7PsdeCBB2b307HTejIpR6S1bFLeSZOl0phSXksFu9mRCmszTuQqyXbDhg3LJimlTg2puJdOjKXJZelk2SuvvFKal0r85S9/iW7dumUtOUuKl6ecckr0798/u8oyXXmZJi6lY6y99tpZ5krZKRVg03ue2sCnzJOKf+k9uO+++7LJZ6kom7Jb+v60VvQ+++yTHTsVYAEASqRCX8pmqTNWynfpPE+apJUma80oZZuUR9I+s3PVXzqHU1IsTC1CXfUH/KECkAtXXnllOsNRePHFF2e5zzbbbFNo2rRp4YMPPijd9uWXXxbmmWeewtprr1267aCDDio0aNCg8Oqrr5Zu++abbwpt27bNnuOjjz4q3d6nT5/sVmLrrbcuLLvssr871jPOOGOm45To1KlTYbfddiu9f9xxx2X73nHHHTPtO3369N99nnSsjTbaqPD1119ntzfeeKOwyy67ZMc78MADS/d78skns23XX399ue9/8MEHy20fM2ZMoXHjxtn7WNYJJ5yQ7Vd23CV/H2uuuWZh6tSppdt/+OGHwrzzzlvYe++9yx0jHbt169al27/77rvs+9N7NSt33nnnH/6dJ2mf448/vtL/DkpewwYbbFDuvT700EMLjRo1KowfP/53nxcA6puSn53Dhg3Lssdnn31WuO222wrzzz9/oVmzZtn9Eikf/PLLL+W+P/38X2CBBQp77LFH6baUl9Ix27VrV/j2229Lt999993Z9nvvvbd02worrFDo0KFDuZ/RDz/8cLZfykUl7rrrrmzbySefXO75d9hhhywDjho1qnRb2i+NvWxuu+SSS7LtCy64YOH7778v3X7MMcfMMuNV9D5VdCv7Wtq3b59l0BIjRowoNGzYsLDrrruWbksZJ33fTjvtVO45Pv744yyvnHLKKeW2pzyY8lzJ9pR30/ffeuutvzvmli1blst6AAAlXnrppSxPPPLII9n9dA5lkUUWKRxyyCHl9it7PmrdddfNstSkSZNmeV6vJOekXPn4449nXw8ePLj08ZTvNt988zn0KoG6RKtPqCemTZuWzQLfZpttspnTJVL7yHQl3lNPPZXNPE8efPDBrIVT2ZnmqTXSzjvv/IfPk2ZOpyvqKmo9VRW33357LL/88ll7yRml2e5/JL3mdEVcunXv3j2bsZ1mvqfe6CVS66o0m3vDDTfMZp2X3FJbqNQGs6Tl1vDhw7MrBtOs9rLS7PBZSTP4GzVqVHo/XbGXZo+n2V9lnyvtk660K3muNHsrzRL73//+N1O70bLvdZJmpE+ZMiWq+99BiTSzvex7nWaapeN88skns/WcAFDfbLDBBln2SG00UxeE1D0hXTFX9sq79LO/ZK3k1Er822+/zXJGapGermib0V//+tdyVwyWtA9NV/wlo0ePztaLSV0FUq4pkfJNugKwrAceeCB7/tTloKzU+jOdk0otyctKLcHLXmFX0h0gXV2YWpbPuL1kTH/kggsuyLJR2VvZ15LaaaYMWqJHjx7Z60njn9F+++1X7n7qgJDe13S1X9nMla7oS1cGlmSukvcqXfGYujAAAFTlar+0ZEzqnpWkcygpu910003Z+ZOKpKv+0hIvaa2/2ZGuEEzHr0yLUKD+UviDeiK1NkonM9L6LTNaeumlsxMjJeudpIJOWqtlRhVtm9FRRx2VFctSK6R0UiW1hEqtMqsqrYWT1qepqnQCKp1ESsXMtG5NKpalQlrJibaSdV1Sq6m0Dl9JkbDkllqNppaaSUmha8b3IZ2QmrF1aIm05l5Z6bmS1KJhxudKBbmS50ptVVMb0HTiLYXHFPBSuEuhsERagzGdcBswYEDWFiute5PWYUytqqrj30GJjh07lrtf8lpnVZAEgPqupKB12223xWabbZYVnCpqmZ7WjEvFrLSuXLt27bI8cP/995euLVeZn8clOSXlrxnN+HM/7ZvWKy5btCvJAmWPNavnLimWpcJmRdtnNyOkvJiKpGVvZZ9/VnklvZ8lLdR/L3OlImZ6P2bMXKmFfEnmSt+XWmyltqspT6W2n+nvr6K/AwCAGaXCXirwpaJcWjZm1KhR2S2dj0rr8qVJ5NVVyKtssRCov6zxB1SrdDJm5MiR2VVoqdiWrthLa7+kNe5SgWpOSydwSk4ipRM5Sy21VLYmzTnnnFPaRz0Vu1LRb1YLL89q/cHZMWPf9fRcSbryMM04n1Hjxr99LPfr1y9bS/Cuu+7KZqGnNWrSmjpp3ZyePXtmM8jSCcXnnnsu7r333myftK7OWWedlW1LBdjqUPaKxbJK1s8BAGYuaKUr95J0lX1axzddWZ8yUsnP5+uuuy67oi09ntbWS1kk/cxNP+vTxKfa9PN4Vs9dmzJCRZkrZaU0iaqicZbNSSk7pb+Lu+++O5uIla6ETH8PKU/NuD4iAEBZ6RxN6laQin/pNqN0rmmjjTaq8HuPP/74WGeddeKSSy4p7er0e1KxMO2fioUzdjsAKEvhD+qJVLxq0aJFdsJpRu+++240bNiwdNZ2p06dstlJM6poW0VSO6vU0iDdJk+enC1ufMopp8QxxxyTzWifnRadJRZbbLF48803o7psvvnm2ZVyAwcOjH333Tcba3qOYcOGxRprrPG7CySn96XkfSg7q/ybb76Z7Znt6bmSdHKvpCD5R/untlvplmaup/ar6eRUOllYYtVVV81u6T2+4YYbspasKWzutddef+rfAQDw55UU89KM7vPPPz+OPvrobHuavJPabqeWlGWzUToBVBUlOaWku0BZM/7cT/um7PPDDz+Uu+ovZYGyxyqWkuefVV5JE7tShvujDJUKkCmzLbHEEn/4nKklfLr95z//iWeeeSbLhWk2/cknn5w9Xpn8CgDUH6mwl87xpI4BM0o5784778wyRUXnm9L5qVTISx2f0oT52b3qr6RYCDArWn1CPTrplGYYpZnMH3/8cen21HYgFYvSTPRWrVqVXhn37LPPZmurlEjrzszqiriyUhGsrNRSM60rk068lKxDV3KiJq1190dSK8sRI0ZkQam6ZpOndqRpnJdeeml2P639kloznHTSSTPtm9baKRlnWt8mXZF30UUXldsnncSbXem9Te9zKjxWtC5fasWZpHacP//880wnsNLJuZJWnqnYOON7ULIu46zafVbm3wEAUD3SyZl0FeCQIUNKf76XXIVW9mf5888/n2Wwqkjr9aYckNqHlm1TmVqOvv322+X2Te1HU/aZMcOcffbZWYFr0003jWIq+1rK5sU0GSxdkZfG/0fSxLP0HqeOEzPmpXS/JLOmtY1T3isrFQDTZKiyeSrl19nJrgBA/ZFadKbiXuosldZ1nvHWt2/fbKJVWuv5j9p3Dh06dLaes2yxcMbzRgAlXPEHOXPFFVdkLTZndMghh2QzltPJn1TcOeCAA7IiVpohlE5qpDYBJY488sjsirINN9wwDjrooOxER1r3JK3vkgqAvzfjORWVUgvLNEs6rU2X1lBJJ5XSlXYlM8p79eqV/XnsscfG3/72t2jSpEnW0rKimdup9VWaEf+Xv/wla2OZvjeNIYWmNGNq+eWXr/R7lE5mpXUDBw8enK1BmEJTuvovzcZPxc70GtKY0oz5W2+9NWsLmgJbej3pfUxX3G211VaxySabZEXJ1EIqzTyfnZngqaiWCoe77LJLrLjiitnrT1fhffrpp9maPul9S+/Xe++9lxUaU1EyFU7T31UqfqYCXfqeJJ0MS21Ut91226womMJkKmam5/i9E2Kz++8AAKg+KdOkPHPVVVdlrZnSCaJ0oij9HE85Ka0Jk7JN+rmf1hiuipRl0rHSz/iUm1JmOu+882LZZZctd8yUu9IViCmLpYlAKU+lglqaGJRajZd0KCimM844I8tsq622Wuy5557ZibX0WtI6gukE2R9JryFlntRxIr3G1FI1ZdH0PqdMtc8++8Thhx+etedKJ+XS3026MjAVAVNL9lQ0TBPQSqQMmq6STPkxrY+YriRMa/cAAPVXOjeVzsWkc0QVSd2Z0jmfNJE+dcWqSDonlW6PP/74bD9v6hCRshzALBWAXLjyyivTVOZZ3j777LNsv1deeaWw8cYbF+aee+5CixYtCuuuu27hmWeemel4r776amGttdYqNGvWrLDIIosUTj311MK5556bHWvMmDGl+/Xp0ye7lbjkkksKa6+9dqFdu3bZ9y622GKFI444ojBhwoRyxz/ppJMKCy+8cKFhw4bZMT/66KNse6dOnQq77bZbuX2/+eabQt++fbP9mzZtmo0n7TNu3LjffU/SsTbffPMKH7vqqquy503vW4mhQ4cWevXqVWjevHlhnnnmKXTv3r1w5JFHFr788svSfaZOnVro379/YcEFF8z2W2+99QrvvPNO9nr322+/mf4+XnzxxQqf/7HHHsv+Hlq3bl2Ya665svdp9913L7z00kvZ4+m1HXjggYWlllqq0LJly2y/3r17F2655ZbSY6S/y5122qnQsWPH7L1u3759YYsttig9Rok0juOPP77cttn5dzCr15DGnranPwGAwmz9/J82bVr28z7dUp6YPn16YeDAgVleST/He/bsWbjvvvuyjJO2lUgZKR3zjDPOmOmYFf2Mv/322wtLL710dsxlllmmcMcdd8x0zOSHH34oHHrooYWFFlqo0KRJk0K3bt2y50jjmvE5UiYpa1ZjKskIt956a5Xfp7KGDRtWWGONNbLM1apVq8KWW25ZePvtt8vtk15/OtbXX39d4THS+7HmmmtmeSrdUrZKr2fkyJHZ4x9++GFhjz32yP5eUiZr27ZtlovSc5f17rvvZhk3jSU934x5FQCof1I2Sflh4sSJs9wnnetJWSud56koV5XNUDPmo9/LOelcXHpsVue9gPqtQfrPrMuCAL9JM8DTlWFpxnhJeyp+bVnapk2bbFZ5mjkPAAAAAADFYI0/oEKpnVJZaR2U1PYotY6qz0W/Gd+XJK3Xk6Qe6wAAAAAAUCzW+AMqlNZTSYWspZdeOltX7vLLL4/vv/8++vfvH/XZzTffnK3Nk9bQm3vuueOpp56KG2+8MVsXMK3PBwAAAAAAxaLwB1QoFbZuu+22GDp0aDRo0CBWXHHFrPi39tprR33Wo0ePaNy4cQwaNCgrhC6wwAJxyCGHZG0+AQAAAACgmKzxBwAAAAAAADlgjT8AAAAAAADIAYU/AAAAAAAAyAGFPwAAAAAAAMiBxpFDzXv2LfYQgDrkuxfPL/YQgDpirlwmp5nJUkBlyFLA7JKlAGYmSwHVnaVc8QcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA50DhqgeHDh2e3sWPHxvTp08s9dsUVVxRtXAAAdYEsBQBQdbIUAJAnRS/8DRgwIE488cRYaaWVokOHDtGgQYNiDwkAoM6QpQAAqk6WAgDypuiFv4svvjiuuuqq2GWXXYo9FACAOkeWAgCoOlkKAMiboq/xN3ny5Fh99dWLPQwAgDpJlgIAqDpZCgDIm6IX/vbaa6+44YYbij0MAIA6SZYCAKg6WQoAyJuit/r8+eefY+jQoTFs2LDo0aNHNGnSpNzjgwcPLtrYAABqO1kKAKDqZCkAIG+KXvh7/fXXY4UVVsi+fvPNN8s9ZkFlAIDfJ0sBAFSdLAUA5E1RC3/Tpk2LAQMGRPfu3aNNmzbFHAoAQJ0jSwEAVJ0sBQDkUVHX+GvUqFFstNFGMX78+GIOAwCgTpKlAACqTpYCAPKoqIW/ZLnllosPP/yw2MMAAKiTZCkAgKqTpQCAvCl64e/kk0+Oww8/PO67774YPXp0fP/99+VuAADMmiwFAFB1shQAkDcNCoVCoZgDaNiwYYWLJqdhpfup33plNe/Zt9rGB+Tfdy+eX+whAHXEXEVdHblishRQbLIUMLtkKYCZyVJAdWepokeuxx57rNhDAACos2QpAICqk6UAgLwpeuGvT58+xR4CAECdJUsBAFSdLAUA5E3RC39PPPHE7z6+9tprz7GxAADUNbIUAEDVyVIAQN4UvfC3zjrrzLStbE/1qvRSBwCoL2QpAICqk6UAgLz5bQXjIvnuu+/K3caOHRsPPvhgrLzyyvHwww8Xe3gAALWaLAUAUHWyFACQN0W/4q9169Yzbdtwww2jadOmcdhhh8XLL79clHEBANQFshQAQNXJUgBA3hT9ir9ZWWCBBWLkyJHFHgYAQJ0kSwEAVJ0sBQDUVUW/4u/1118vd79QKMTo0aPjtNNOixVWWKFo4wIAqAtkKQCAqpOlAIC8KXrhL4WotGhyClZlrbrqqnHFFVcUbVwAAHWBLAUAUHWyFACQN0Uv/H300Ufl7jds2DDmn3/+mGuuuYo2JgCAukKWAgCoOlkKAMibohf+OnXqVOwhAADUWbIUAEDVyVIAQN4UvfCXDB8+PLuNHTs2pk+fXu4xbRUAAH6fLAUAUHWyFACQJ0Uv/A0YMCBOPPHEWGmllaJDhw5ZX3WoyBorLhaH7rpBrLhMx+gwf+vY8dChce//fluEe+iAf8QuW61a7nsefvrt2LrvhdnXHTu0jWP22STWWXmJWKBdqxj99YS48YEX4/TLHoopU6eV+75+u6wfe2y/RnTs0Ca+GT8xLrnlyRh0+UNz6JUCc8pXX30VQwafEU8/+WT8/PNPsWjHTnHiyQNj2eW6Z49/M25cDBl8Zjz7zFPxww8/xIq9Voqjj+0fnTp1LvbQoZQsRW3KUt06tY/zjv1bLNV1wWg9d/Nsn5v/+1KcMvSBmDq1/IlUoG7bdMP14ssvv5hp+1//9vc48KBD4sILzssy1JjRo6NNm7ax7vobZNvnmWeeoowXZkWWYk5lqbKaNmkcT1x7eCy/5CLR+6+nxuvvfVGat0Y+cOJM+/fZ9cx44Y2Pa+R1AcVx0QXnxcUXnl9uW+cuXeLu+x7Mvv7ll1/irEGnxYP/fSAmT54cq6+xZhzb//hoN998RRoxdUnRC38XX3xxXHXVVbHLLrsUeyjUci2bN4s33vsirrn72bh58D4V7vPQ02/FvsdfV3r/l8lTS79esssC0bBBw+h78k3xwWdfx7KLLxQX9N8pO+4xZ99Zut9ZR+4Q66+6VLbtzfe/jLatW0SbVi1r+NUBc9r3EybE7v/YKVZapXdccPGl0aZtm/j0k0+iVavW2eOFQiH6HXxgNG7cOIacd2HMPffccc3VV8W+e/4z7rjn/mjRokWxXwJkZClqU5ZKBcDr73shXnv3s5jww6TovsQi2T4NGzaI48+/dw68SmBOuf7m22L6tN8mUI4a9X7su9c/Y8ONN4mxX4+Nr8eOjcMOPyoWW2zxrEB48oknZNvOGnJuUccNM5KlmFNZqqyB/bbOJkilwl9FNt333Hjng9Gl97+ZMPFPjx+ofRZbvFsMvezK0vuNGjcq/fqM0wfGk48/HmcMHpJNnDr1lJPisEP6xtXX31Sk0VKXFL3wl1WrV1+92MOgDkizpNLt90yePDW++uaHCh975Jl3sluJj7/4Jpbo1D72/stapSer0gmtvXdYK3r95ZR4/5Ox2bZPvvymWl8HUDtccfmlscCCC8ZJp5xaum2RRRYt/fqTTz6O10e8FrfffV8svni3bNt/jjsh1uuzRjz4wP2x3Q5/Kcq4YUayFLUpS6Vt6Vbi09HfxdordYs1ei5Wba8DqB3atm1b7v4Vlw2NRRftGCutvEp2xdTgc84rfWzRjh3joEP6xb+POiKmTp2aTayC2kKWYk5lqRIbrbFMrL/q0rHTEZfFJmsuW+E+346f+IfHAeq+xo0axXzzzz/T9tR16s7bb4/TBp0ZvVddLduWOlRts+Vm2bmqHsuvUITRUpc0LPYA9tprr7jhhhuKPQxyYq2VusUnw0+NEXf2j3P+/ddo2/r3r9RrNXfz+Pb7SaX3N1+7e3z0xbjYbO3l4p37Toh37x8QFx7392jTypU9kDePP/ZoLLvscnH4oQfHOmutFjtuv03cfustpY9PmTw5+7NZ02al2xo2bBhNmzaNV195uShjhorIUtSmLDWjrovOFxuuvnQ8+fKoGhgtUFuk3HT/fffENtttP8s2iT/+8GPWQUHRj9pGlmJOZqn2beeJC/vvFHv2vyYm/fTr75wVuW3Ivtlxhl9xaGze59elKID8+eTTT2KDddaMzTZeP4458l8x+ssvs+1vv/VmTJ06JXqv9tvElC5dF4sOHRaKEa+9VsQRU1cUJXEfdthhpV+nRZOHDh0aw4YNix49ekSTJk3K7Tt48OAijJC6KM1Av/vREdks866LzBcDDtoy7j5//+iz21kxfXqhwhNR+/+tT7k2n50XmS/rp77dBj1jr/7XZif5Bx2+Xdxwxp6x6b6/zVgF6r7PP/8sbrn5xthlt3/GnvvsF2+98UacfurJ2c+hrbbZNjp36ZoFqnOHnBX9jz8xmjdvHtdec1V8NWZMfP3118UePvWcLEVtzVIlHrvqsFhhqUVjrmZN4rLbnooTL7p/Dr0KoBgefXRYNjM9ZaiKfPfdtzH04gtj+7/8dY6PDSoiS1GsLDX0xH/Epbc9Fa+8/Wl2/mlGE3/6JY4664549rUPsu/ZZoMV4pbBe8eOh10a9z/+RhFeFVBTuvfokXWh6ty5S3ae6ZKLLoh/7rpz3H73vfHNuHHZz6NWrVqV+5627drFuHHOSVFLC3+vvvpqufsrrPDrpalvvvlmue2zs6ByWuQy3coqTJ8WDRr+1g+X+uHWh367AuetUV/GG+9/Ee/cNyBrL/W/F94rt+9C87eOe84/MO4Y9mpceeczpdsbNmiQnaDas/+1MerTX1t97j/g+nj2xqOjW6f2pe0/gbov/RK17HLLxcH9fv2lf+mll8nWprn1lpuyk1YpYKUWVSf0PzbWWn2VaNSoUdZeYc211s7W/4NikqWorVmqxC5HXRFzt5wreiyxcAzst00cuuv6MfjqYXPkdQBzXmpFtcaaa0f79gvM9NiPP/4YffffN7outljsd0DfoowPZiRLUYwsdcBOfWKeFnPFGVc8PMtjfDN+Ypx73aOl919++9PoMH/rLEsp/EG+rLlWn9Kvl1hyqejeY/nYdMN146EH/xtzNZurqGOj7itK4e+xxx6rtmOdeuqpMWDAgHLbGi2wcjTpsEq1PQd1U5ph9fV3P8Rii85f7mRVCkwPXnpIPPf6h3HgSTeW+54x4ybElCnTSot+ybsffZX9ueiCbRX+IEfmn3/+7ARUWV27do1hjzxUen+ZZZeLW+64O5vBPmXKlGwtm53/9pesRSgUkyxFbc1SJT7/anz257sfjsk6KFzwn51iyLXDK7xyEKjbvvzyi3j+uWfKrelXYuLEH+OAffeKli1bxtnnXjDTlVRQLLIUxchS66y8RPTu0SUmPD+k3H5PX39k3PTfl2Lv466t8DgvvvFJrNd7qTk0aqBY0tV9nTp1js8+/TRWXW317DzU999/X+6qv2+/+Sbmm2/mNQGh1qzxN23atHj99dfjp59+mumxtC09ltot/JFjjjkmJkyYUO7WeIFeNTRq6pKF288b7Vq3jDHjvi83O/2hSw+JV9/5NPY5/rqZrtp59rUPo0mTRtFlkflKt6Ur/ZJPR387B0cP1LQVeq4YH3/0Ubltn3z8cSy00MIz7TvPPPNkRb9PPvk467O+znrrz8GRQsVkKWpjlqpIw4YNoknjRtmfQP7cfecd0bZtu1hr7XVmutJvv733zIp955x/UTRr9tu6yVAbyFLM6Sz1r0G3xSp/PTV6/+207LbNQRdl23c5+so44fx7Z3mcHksuXC6PAfk0aeLE+Oyzz2K++efPJqI3btwkXnju2dLHP/7owxg9+stY/v+vUoffU7RVta+99to4//zz4/nnn5/psfSLwR577BH9+vWLf/zjH797nPTLw4y/QGinkE8tmzfNZkmV6Lxwu6x91HffT4pvJ0yMY/fdLO4a/loWhtKaM6ccsk188Nm4rMd66Ymqyw7JCnjHDL4z5m8zd+mxvvrmh+zPR58fmfVZv+SEneOIM27PTlANOXrHGPbsO+WuAgTqvn/sulvs9o+d4rKhF8dGG28ab77xetx22y1x3Aknlu7z8EP/jTZt2mZr/b3//sgYdOrAWHe9DWL1NdYs6tghkaWojVnqb5uuFFOmTos3R30Zv0yeGr2W6RgnHbRV3PbwyzF16h+fPAXqllQUSYW/LbfeJho3bjxD0W+P+Pnnn2LgaWfExB9/zG5Jm7ZtsxbqUGyyFHM6S3025rtyx/tx0q8tYj/87Ov4Yuyv3RJ23rJ3TJkyNV579/Ps/tbrLR+7bb1a7H/iDXPwlQJzwllnnB591lk3Oiy0UHw9dmxcdMF50ahRw9h0sy2yCejbbr99nDnotGjVunXMPffccdrAk2P5FXpGj+UV/qjFhb/LL788Dj/88AoDf/qF4cgjj8wC2B8FLOqPFZfpFA9fdkjp/UGHb5/9ee09z8XBA2+O5botnAWkeedpHqO/nhDDnn03Trzwvpg8ZWq233qrLhWLd2yf3T54+JRyx27e89e1JtKs9R36XRKDj/pLPHJ5v5j40+R4+Om34+jBd8zR1wrUvOW694jB55wf5w4ZnC2gvPAii8SRR/07Nt9iq9J90uLKKWR9M+6brDXoFlttHfvud0BRxw0lZClqY5aaOm16HLb7hlnHhLQuUioSXnTzE3FembVqgPx47tlnspnn22z36+dJiXfefiveeH1E9vUWm25Y7rEHHh4eCy+8yBwdJ1RElmJOZ6nZdfTem0THDm2zSVPvffxV7HL0FXHnsNeq/fUAxfXVV2Pi6CMOi/Hjx2cTo3qu2CuuveGWrONUcsRR/46GDRrGv/odHJOnTM4moR/7n+OLPWzqiAaF2enPUwPat28fL7zwQnTu3LnCxz/66KNYZZVVspOulVVy4gFgdnz34vnFHgJQR8xVtClTM5OlgNpClgJmlywFMDNZCqjuLFW0Nf4mTpyYLU45Kz/88ENMmjRpjo4JAKCukKUAAKpOlgIA8qpohb9u3brFM888M8vHn3rqqWwfAABmJksBAFSdLAUA5FXRCn9///vf4z//+U+8/vrrMz02YsSIOO6447J9AACYmSwFAFB1shQAkFdFW+NvypQpsdFGG2UzqDbYYINYaqmlsu3vvvtuDBs2LNZYY4145JFHokmTJpU+tl7qQGXopQ7UxXVpZCmgtpClgNklSwHMTJYCqjtLFa3wVxKyzj777Ljhhhvi/fffjzSUJZZYIptR1a9fv2jatGmVjitgAZUhYAF18WRVIksBtYEsBcwuWQpgZrIUkKvCX00RsIDKELCAunqyqqbIUkBlyFLA7JKlAGYmSwHVnaWKtsYfAAAAAAAAUH0U/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAdqVeGvUChkNwAAKk+WAgCoOlkKAMiDWlH4u+aaa6J79+7RvHnz7NajR4+49tpriz0sAIA6QZYCAKg6WQoAyJPGxR7A4MGDo3///tG3b99YY401sm1PPfVU7LfffjFu3Lg49NBDiz1EAIBaS5YCAKg6WQoAyJsGhSL3MOjSpUsMGDAgdt1113Lbr7766jjhhBPio48+qvQxm/fsW40jBPLuuxfPL/YQgDpirqJPmZqZLAUUmywFzC5ZCmBmshRQ3Vmq6K0+R48eHauvvvpM29O29BgAALMmSwEAVJ0sBQDkTdELf4svvnjccsstM22/+eabo1u3bkUZEwBAXSFLAQBUnSwFAORN0ZsspHYKf/3rX+OJJ54o7aX+9NNPx/DhwysMXgAA/EaWAgCoOlkKAMibol/xt/3228fzzz8f8803X9x1113ZLX39wgsvxLbbblvs4QEA1GqyFABA1clSAEDeNCgUCoXIGYsoA5VhEWWguhdRrutkKaAyZClgdslSADOTpYDqzlJFv+IPAAAAAAAA+POKNteqYcOG0aBBg9/dJz0+derUOTYmAIC6QpYCAKg6WQoAyKuiFf7uvPPOWT727LPPxrnnnhvTp0+fo2MCAKgrZCkAgKqTpQCAvCpa4W/rrbeeadvIkSPj6KOPjnvvvTd23nnnOPHEE4syNgCA2k6WAgCoOlkKAMirWrHG35dffhl77713dO/ePWuh8Nprr8XVV18dnTp1KvbQAABqPVkKAKDqZCkAIE+KWvibMGFCHHXUUbH44ovHW2+9FcOHD89mVS233HLFHBYAQJ0gSwEAVJ0sBQDkUdFafQ4aNChOP/30WHDBBePGG2+ssMUCAAAVk6UAAKpOlgIA8qpBoVAoFOOJGzZsGM2bN48NNtggGjVqNMv97rjjjkofu3nPvn9ydEB98t2L5xd7CEAdMVfRpkzNTJYCagtZCphdshTAzGQpoLqzVNEi16677hoNGjQo1tMDANRpshQAQNXJUgBAXhWt8HfVVVcV66kBAOo8WQoAoOpkKQAgrxoWewAAAAAAAADAn6fwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA50Hh2drrnnntm+4BbbbXVnxkPAEDuyFIAAFUnSwEAVHPhb5tttpmtgzVo0CCmTZtWiacHAMg/WQoAoOpkKQCAai78TZ8+vRKHBACgLFkKAKDqZCkAgNlnjT8AAAAAAACoL1f8zWjixInx+OOPx6effhqTJ08u99jBBx9cXWMDAMglWQoAoOpkKQCAaiz8vfrqq7HZZpvFpEmTsqDVtm3bGDduXLRo0SLat28vYAEA/A5ZCgCg6mQpAIBqbvV56KGHxpZbbhnfffddNG/ePJ577rn45JNPolevXnHmmWdW9nAAAPWKLAUAUHWyFABANRf+XnvttfjXv/4VDRs2jEaNGsUvv/wSiy66aAwaNCj+/e9/V/ZwAAD1iiwFAFB1shQAQDUX/po0aZKFqyS1UEj91JPWrVvHZ599VtnDAQDUK7IUAEDVyVIAANW8xl/Pnj3jxRdfjG7dukWfPn3iuOOOy3qpX3vttbHccstV9nAAAPWKLAUAUHWyFABANV/xN3DgwOjQoUP29SmnnBJt2rSJ/fffP77++usYOnRoZQ8HAFCvyFIAAFUnSwEA/L4GhUKhEDnTvGffYg8BqEO+e/H8Yg8BqCPmqnSvhLpJlgIqQ5YCZpcsBTAzWQqo7ixV6Sv+AAAAAAAAgNqn0nOtunTpEg0aNJjl4x9++OGfHRMAQG7JUgAAVSdLAQBUc+GvX79+5e5PmTIlXn311XjwwQfjiCOOqOzhAADqFVkKAKDqZCkAgGou/B1yyCEVbr/gggvipZdequzhAADqFVkKAKDqZCkAgDm0xt+mm24at99+e3UdDgCgXpGlAACqTpYCAKjmwt9tt90Wbdu2ra7DAQDUK7IUAEDVyVIAAFVs9dmzZ89yiygXCoUYM2ZMfP3113HhhRdW9nAAAPWKLAUAUHWyFABANRf+tt5663IBq2HDhjH//PPHOuusE0sttVRlDwcAUK/IUgAAVSdLAQD8vgaFNDUqZ94ZPbHYQwDqkI7tWhR7CEAd0bLpbyeZ8mzMhCnFHgJQh0zL36+UQA1ZeN6mUR+MHDOp2EMA6pD2rZoVewhAHdGmRaOaWeOvUaNGMXbs2Jm2f/PNN9ljAADMmiwFAFB1shQAQDUX/mZ1geAvv/wSTZvWj5lbAABVJUsBAFSdLAUAUE1r/J177rnZn6mP+mWXXRZzzz136WPTpk2LJ554Qi91AIBZkKUAAKpOlgIAqOY1/rp06ZL9+cknn8QiiyxSrn1CmlHVuXPnOPHEE6N3795RbNb4AyrDGn/AnFjjry5lKWv8AZVhjT9gTqzxV5eylDX+gMqwxh9Q3Wv8zfYVfx999FH257rrrht33HFHtGnTZrYHAwBQ38lSAABVJ0sBAFTzFX91iSv+gMpwxR8wJ674q0tc8QdUhiv+gDlxxV9d4oo/oDJc8QdU9xV/DaOStt9++zj99NNn2j5o0KD4y1/+UtnDAQDUK7IUAEDVyVIAANVc+EuLJW+22WYzbd90002zxwAAmDVZCgCg6mQpAIBqLvz9+OOP2aLJM2rSpEl8//33lT0cAEC9IksBAFSdLAUAUM2Fv+7du8fNN9880/abbroplllmmcoeDgCgXpGlAACqTpYCAPh9jaOS+vfvH9ttt1188MEHsd5662Xbhg8fHjfccEPcdtttlT0cAEC9IksBAFSdLAUAUM2Fvy233DLuuuuuGDhwYBaomjdvHssvv3w8+uij0bZt28oeDgCgXpGlAACqTpYCAPh9DQqFQiH+hNQ//cYbb4zLL788Xn755Zg2bVoU2zujJxZ7CEAd0rFdi2IPAagjWjZtUO3HrI1ZasyEKcUeAlCHTPtzv1IC9cjC8868Nl8es9TIMZOKPQSgDmnfqlmxhwDUEW1aNKqZNf5KPPHEE7HbbrvFQgstFGeddVbWXuG5556r6uEAAOoVWQoAoOpkKQCAamj1OWbMmLjqqquyWVRpRtWOO+4Yv/zyS9ZiwQLKAAC/T5YCAKg6WQoAoBqv+Es91Jdccsl4/fXXY8iQIfHll1/GeeedN7vfDgBQr8lSAABVJ0sBAFTzFX///e9/4+CDD479998/unXrNrvfBgCALAUA8KfIUgAA1XzF31NPPRU//PBD9OrVK3r37h3nn39+jBs3bna/HQCgXpOlAACqTpYCAKjmwt+qq64al156aYwePTr23XffuOmmm7IFlKdPnx6PPPJIFr4AAKiYLAUAUHWyFADA7GlQKBQKUUUjR47MFlS+9tprY/z48bHhhhvGPffcE8X2zuiJxR4CUId0bNei2EMA6oiWTRtU6/Fqa5YaM2FKsYcA1CHTqv4rJVDPLDxv03qRpUaOmVTsIQB1SPtWzYo9BKCOaNOiUfVe8VeRtKjyoEGD4vPPP48bb7zxzxwKAKDekaUAAKpOlgIAqOYr/morV/wBleGKP6BYV/zVVq74AyrDFX9Asa74q61c8QdUhiv+gFp1xR8AAAAAAABQOyj8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA4o/AEAAAAAAEAOKPwBAAAAAABADij8AQAAAAAAQA40jlpg/Pjx8cILL8TYsWNj+vTp5R7bddddizYuAIC6QJYCAKg6WQoAyJMGhUKhUMwB3HvvvbHzzjvHjz/+GK1atYoGDRr8NrgGDeLbb7+t9DHfGT2xmkcJ5FnHdi2KPQSgjmjZ9LecUlvURJYaM2FKNY8SyLNpxf2VEqhDFp63adSHLDVyzKRqHiWQZ+1bNSv2EIA6ok2LRnWj8LfEEkvEZpttFgMHDowWLarn5LvCH1AZCn9AXS781USWUvgDKkPhD6jLhb+ayFIKf0BlKPwBuSv8tWzZMt54443o2rVrtR1T4Q+oDIU/oC4X/moiSyn8AZWh8AfU5cJfTWQphT+gMhT+gOou/DWMItt4443jpZdeKvYwAADqJFkKAKDqZCkAIG8aF3sAm2++eRxxxBHx9ttvR/fu3aNJkyblHt9qq62KNjYAgNpOlgIAqDpZCgDIm6K3+mzYcNYXHaZFlKdNm1bpY2r1CVSGVp9AXW71WRNZSqtPoDK0+gTqcqvPmshSWn0ClaHVJ1DdrT6LfsXf9OnTiz0EAIA6S5YCAKg6WQoAyJuirvE3ZcqUaNy4cbz55pvFHAYAQJ0kSwEAVJ0sBQDkUVELf6lveseOHavUNgEAoL6TpQAAqk6WAgDyqKiFv+TYY4+Nf//73/Htt98WeygAAHWOLAUAUHWyFACQNw0KheKuxN6zZ88YNWpU1l6hU6dO0bJly3KPv/LKK5U+5jujJ1bjCIG869iuRbGHANQRLZs2iNqmJrLUmAlTqnGEQN5NK+6vlEAdsvC8TaM+ZKmRYyZV4wiBvGvfqlmxhwDUEW1aNJqt/RpHkW2zzTbFHgIAQJ0lSwEAVJ0sBQDkTdGv+KsJrvirH/57963x4N23xtgxo7P7HTt3jR132yd69V4juz/5l1/iyosGx1OPPhxTJk+OFVZZLfbrd0zM27Zd6TFGvPx83HDFRfHJh6Nirrmax7qbbBH/2PPAaNS46DVx5iBX/NVfEyf+GBeef248NnxYfPftN7HkUkvHEUcfG8su1710nw8//CDOPfvMeOWlF2PqtGnRteticcbZ50aHDgsVdewUR2284q8muOKv/hjxyktx43VXxnvvvh3fjPs6Th50Tqy1zvqlj3/7zbi45Pyz48Xnn4kff/ghlu/ZKw45/N+xSMdOMx0r/VpxZL/944Vnn5rpOOSbK/7qhxuuuiye/N+w+PSTj6JZs7li2e7Lx959D42OnbqU7nPfnbfG8IcfiPfffScmTZoY9wx7Ouaep1W541x35dB47ukn4oP3RkbjJk3i3uHPFOHVUCy18Yq/muCKv/rh1usuj2efeDS++PTjaNqsWSy13PKx276HxCIdO5fu89034+LKi4bEay8/Fz9NmhgLL9o5dtxlz1i9zwal+3zx2Sdx5UVnxztvjoipU6ZE58W6xc57HBA9Vly5SK+MOc0Vf/XDqy+/FNddc0WMfPutGDfu6zh98LnRZ93fPgseG/5I3HnbzfHuO2/F9xMmxDU33R5LLLl06eNffvlFbLf5hhUe+5RBg2P9DTeZI6+DunHFX9HX+IOqajd/+9hln4PjrKHXx5mXXBfdV1w5Tj320Pj0ow+yx6+44Kx48Zkn44gTTo+Tz7k0vhv3dZx23OGl3//RqPfipKMPjhVXWT3OvvSGOPz40+LFpx+Pa4aeV8RXBcxJJx7fP55/9pk4aeDpcfMd98Sqq68R++/9zxj71VfZ45999mnsuevfo3OXrjH0imvi5tvvjr33PSCaNRXKgXz46eefYvFuS0a/I46tsJB37BGHxJdffB6nnHluXHbdrbFAh4XisL57xU8/zXxC89Ybr40GDepHcRzqoxGvvhRb7/C3OP/y6+OMc4fG1KlT48iD9y33efDzzz/HyquuEX/ffa9ZHied1O6z/kax1fY7zqGRA9SMN0e8Eptv+9c446Jr4sSzLoppU6fG8YfvHz//9FPpPmcP7B9ffPZx/GfgkDjvyltjtbXXi0EnHBUfvPdu6T7p3NT0adPi5LMvibMvvT66LLZEnHTMwVnREMiPlJm6LbFkHH5M/wofT58dy6+wYhx48L8qfHyBBRaM+x95vNxt7/36RosWLWK1Ndaq4dFT1xT9sqaGDRv+7gmCadOmzdHxUHessnqfcvf/sVffePDu22Lk229kRcFhD9wVh/1nYPRYcZXs8YOOOiH67rZ9jHzr9Vhy2R7x1GMPReeu3eKvu+2TPd5hkY6x636HxJknHB1/232faN6ifF9/IF/SialHhz0cg8+9IHqt9OtMyv0OOCie+N9jcevNN8aBB/eLC84dEmus1Sf6HXZE6fctumjHIo4aZiZL8Wesuvpa2a0in3/6Sbz95oi46sa7ostii2fbDjuqf2y76Tox/KEHYottdijd9/333o1bbrg6Lrnq5thus3Xm2PiBOef0cy4ud/+o406O7Tbpk10xvHzPlbJtO+y0S/bnay+/OMvj7L7PgdmfD953V42OF2aXLEVVDTjjgnL3DzlmQOyy9fox6r23Y7nle2Xb3n1rROx/6L9jiaWXy+7/dde9455br48P3ns7Fltiqfh+/Hfx5eefxkFHHp8V/JJd9z04Hrjrlvjko1HRpt18RXhlQE1Yfc21s9usbLrFVqVX9lWkUaNG0W6++ctte/yxYdmVfi2cx6a2Ff7uvPPOcvfTYsqvvvpqXH311TFgwICijYu6JQXxZ/43LH7++adYatke8cF772QzUHv06l26zyKdusT8CywYI9/+tfCX/q01aVq+zUizpnPF5Mm/xKiR70T3///lFcinadOmZp8dTWe4em+uueaK1159OaZPnx5PPfG/2O2fe8UB++4ZI999JxZeeJH45577xLrr/9aKAYpNlqKmTJ4yOfuzabOm5U6ONmnSJN4Y8Wpp4S/lr5P6H5ldNdhuPienoL6Y+OOP2Z+tWrUu9lDgT5GlqO7PxXnm+e1zcalll48nH3s4VlptrWg59zzx1GMPZ+edllvh13NO87SeNxbu2Dkee+i+WGyJpbOc9dA9t0frNm1j8SWXKdprAWq/d99+K94b+W4cfnTFVxBSvxW98Lf11lvPtG2HHXaIZZddNm6++ebYc889izIu6oaPP3w/jj5g95g8eXLM1bx5HH3SWbFo567x4ahf14uYe555yu0/b5t22TpeSc+VV4v7brshnhj+YKyxzoYx/ttv4uZrhmaPffetdgqQdy1bzh09ll8hLrvkwujatWu0bTdfPPjA/fH6iNdi0Y4d49tvv4lJkybFlVdcGgf0PSQOOfTweOapJ+PwQw+KoZdfHb1W/vVqYig2WYqa0qlzl1hgwQ4x9IJz4vBjjou5mreIW2+4Jr4e+1W2HmCJ888eFMt1XyHW7LNeUccLzDlpgtQFZ58ey/XoGV0W61bs4cCfIktRXZ+Ll51/ZizdfYXo1PXXTgnJkScMijMGHBU7b7lONGrUOJrNNVf8++TBsdAiv3aSSVebnnTWxTHwP4fGXzddIxo0bBjzztsmThh0wUxrpAKUdc9dt2dL0/RYoWexh0ItVGvX+Ft11VVj+PDhf7jfL7/8Et9//3252+RffpkjY6T40qLIZ192Ywy66OrYdOu/xLmnHhefffzhbH1vKvzttl+/uHjwwPjLhqvGAbtsE716r5k91tD6NFAvnHTqoGwNq43X7xOr9uoRN91wbWy86ebRoEHDKEyfnu2zzjrrxT923T2WXGrp+Ode+8RafdaJ2269qdhDhxrNUmkbNG7cJE46fUh8/unHscUGa8TGa68Ur778QvRefa3spFTy9BOPxSsvPR99Dzu62MMF5qBzzjglPvpwVPQ/eVCxhwI1xnkpKuPis0+NTz8aFUccd1q57ddffkFM/PGHOGnwxTF46HWx9Y7/iEEnHBkff/B+9nj6ffTiIadG63nbxqnnXRFnXXxt9F5z3Tj534fEt9/8NtEKYMblax7+7/2x5TbbF3so1FK1svD3008/xbnnnhsLL7zwH+576qmnRuvWrcvdhp535hwZJ8WXWiCktflS+4Nd9jkoOi+2RNx7+w3Rpm27bNH4H3/4odz+47/7JnusRApc19/3eFx2ywNxzd2Pxipr/rpu4AILLTLHXwsw56X1+i676rp4+vlX4oFHHotrb7w1axO8yCKLxrxt2kTjxo2j6/+va1WiS5fFYszo0UUbM8yJLHXe4NPnyDip/ZZcetm4/Prb4/5Hn407Hngszjj3kvh+wvhYaOFfs1Iq+n35+WexxfqrxXqrLZ/dkuOOPjQO2W/3Io8eqKmi33NPPR6DL7w8W0oB8ujPZqlLnJeqVy4eclq89OyTcfKQS2O+9guUbh/9xWdx/503x8FHnRDL9+odXRZfMnbafd/sHNYDd92c7fP6Ky9k33vE8afFMt1XyNp97n/Yv7MlKR598N4iviqgNnts2MPZkgubbTHzVetQK1p9tmnTptwiymmmyw8//BAtWrSI66677g+//5hjjonDDjus3LaPvp1aI2Ol9isUpseUyVOyoJRO2KcAtXqf9bPHvvj04/j6qzGx5DI9yn1P+vfX9v8XRn1y+EMxX/sFo2u3pYoyfqA4mrdokd2+nzAhnn3mqaytZ5MmTWOZZZeLjz/+qNy+n37ycXTosFDRxgpzIkt993OtnBtGEc0996/t0z//9JMY+c5bsee+fbP7f991r9h86/KzTP+507Zx4KFHxhprrlOUsQI1I/18OffMgfHU44/G2RdeER1MliQnaiJLffLdtBoZK7VL+rdyyTmnx3NPPhoDz7k0FuxQvlD8y88/Z3+W/feVNGzYKKZPL8ywT/n8ndZVLtkHoKI2n2v1WS/atG1b7KFQSxW98DdkyJCZfrDNP//80bt37yx8/ZFmzZplt7KaTpxY7eOk9rl26HmxYu/VY772HeKnnybGk8MejDdfezmOP+OCbMHkDTbbJq688KyYp1WraN6iZVx67qBYctke2a3EnTddHT1XWT0aNmgYzz75aNxxw5Vx+PGnR6NGjYr62oA545mnn4xCIaJz5y7x2aefxJDBZ2T90bfaZrvs8V3/uWccffhhsWKvlWKlVXpna/w98fhjMfSKa4o9dKjRLDWpMKXax0ntlNYy/eLzT0vvj/7yi3j/vXejVavW2fp+jw17KLsCOn394aj347zBp2Vr+a286hrZ/u3mmy+7zWiBBTpEh/+/KhDIh3Sl3/CHHoiTzzgnWrRsGd9+M6503eS0ZlWStqVbyedK+txI+7ZfoEO0at062/bVmNHxw/cTYuyY0TF9+rQY9d672faFF+mYTcSCXJyXmjSp2sdJ7Wzv+cTw/8axp5wdzZu3jO/+/3OxxdxzR7Nmc8UinTpHh4UXjQvOOjn2OOCwmKdV63juqcfitZeei/6nnZPtu9SyPaLlPK1iyKn942+77RNNm80VD993R3w1+otYebVfl6MB8mHSpInx+We//e715RdfxHsj38l+91qww0IxYcL4LCeNGzs2e/yTjz/O/mzXLv3O9etFK0k6f/XaKy/F4PMuLsKroK5oUEjTU3LmndEKf/XBeYMGxOsvvxDffTsu+2WzU9dusd3fd48VVlo1ezz11L/yosHZVXxTpkzO1vTbt98x0abdbyen+h+6T3zw3rtZW9DOi3WLv+6+b/Tq/euJLOqPju2cYKivHn7wv3H+OYPjq6/GROvW88Z6G2wYBx58aMwzz69XtiR33Xl7XHnZ0Bj71Zjo1LlL7HfAQbHOer9eSUz907Jp/VgDdswEhb/6Iq3Z12//PWbavsnmW8cxx58St918Xdx07ZXx3bffZL9sbrzZVrHrnvtl7dZnpc8qy8XJg86JtdbxWVlfTMvfr5RUYL3e3SvcfmT/k2KTLbbJvr7q0gvjmssu+t19Tj/x2Hjo/ntm2mfwhVfECr1WrvZxU7ssPG/TqA9GjlH4qw+26tOzwu2HHD0g1t90q+zrLz//JK6+5Nx4+43X4uefJmWFwG3/umusu/EWpfu//+5bcd1lF8SokW9nS0907Nw1KwL2WlXhr75o36r85AHy6eWXXogD9555OYTNttwmjjtxYNx3z51x8vHHzvT4nvseEHvv92vHleSi886OBx+4N+68f1g2WYX6pU2LRnWn8Dd+/Ph44YUXYuzYsTF9+vRyj+26666VPp7CH1AZCn9AXS/8VXeWUvgDKkPhD6jrhb/qzlIKf0BlKPwBuSv83XvvvbHzzjvHjz/+GK1atSrX9zp9/e2331b6mAp/QGUo/AF1ufBXE1lK4Q+oDIU/oC4X/moiSyn8AZWh8AfkrvC3xBJLxGabbRYDBw7MFk6uDgp/QGUo/AF1ufBXE1lK4Q+oDIU/oC4X/moiSyn8AZWh8AfkrvDXsmXLeOONN6Jr167VdkyFP6AyFP6Aulz4q4kspfAHVIbCH1CXC381kaUU/oDKUPgDqrvwV/TVHzfeeON46aWXij0MAIA6SZYCAKg6WQoAyJvGxXjSe+65p/TrzTffPI444oh4++23o3v37tGkSZNy+2611VZFGCEAQO0lSwEAVJ0sBQDkWVFafTZsOHsXGqZFlKdNm1bp42v1CVSGVp9AXWv1WdNZSqtPoDK0+gTqWqvPms5SWn0ClaHVJ1DdrT6LcsXf9OnTi/G0AAC5IEsBAFSdLAUA5FnR1vh79NFHY5lllonvv/9+pscmTJgQyy67bDz55JNFGRsAQG0nSwEAVJ0sBQDkVdEKf0OGDIm99947WrVqNdNjrVu3jn333TcGDx5clLEBANR2shQAQNXJUgBAXhWt8DdixIjYZJNNZvn4RhttFC+//PIcHRMAQF0hSwEAVJ0sBQDkVdEKf1999VU0adJklo83btw4vv766zk6JgCAukKWAgCoOlkKAMirohX+Fl544XjzzTdn+fjrr78eHTp0mKNjAgCoK2QpAICqk6UAgLwqWuFvs802i/79+8fPP/8802M//fRTHH/88bHFFlsUZWwAALWdLAUAUHWyFACQVw0KhUKhWC0VVlxxxWjUqFH07ds3llxyyWz7u+++GxdccEFMmzYtXnnllVhggQUqfex3Rk+sgREDedWxXYtiDwGoI1o2bRC1RU1mqTETptTAiIG8mlacXymBOmjheZtGfchSI8dMqoERA3nVvlWzYg8BqCPatGhUuwt/ySeffBL7779/PPTQQ1EyjAYNGsTGG2+chawuXbpU6bgKf0BlKPwBdbHwV5NZSuEPqAyFP6AuFv5qMksp/AGVofAH5KrwV+K7776LUaNGZSGrW7du0aZNmz91PIU/oDIU/oC6WvirqSyl8AdUhsIfUFcLfzWVpRT+gMpQ+ANyWfirbgp/QGUo/AF1vfBX3RT+gMpQ+APqeuGvuin8AZWh8AdUd+Gv4WwfEQAAAAAAAKi1FP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP4AAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHGhQKhUKxBwE17ZdffolTTz01jjnmmGjWrFmxhwPUcj4zAMrzuQhUhs8MgPJ8LgKV4TODP0vhj3rh+++/j9atW8eECROiVatWxR4OUMv5zAAoz+ciUBk+MwDK87kIVIbPDP4srT4BAAAAAAAgBxT+AAAAAAAAIAcU/gAAAAAAACAHFP6oF9IiqMcff7zFUIHZ4jMDoDyfi0Bl+MwAKM/nIlAZPjP4sxoUCoXCnz4KAAAAAAAAUFSu+AMAAAAAAIAcUPgDAAAAAACAHFD4o95ZZ511ol+/fsUeBlAkDRo0iLvuuqvYwwCos2QpqN9kKYA/R5aC+k2WYk5Q+GOO2n333bMPt9NOO63c9vRhl7b/WZMnT45BgwbF8ssvHy1atIj55psv1lhjjbjyyitjypQpf/r4QO03ZsyYOOigg6Jr167ZIsiLLrpobLnlljF8+PBiDw3gT5OlgJomSwF5JksBNU2WojZoXOwBUP/MNddccfrpp8e+++4bbdq0qbbjpnC18cYbx4gRI+Kkk07KglWrVq3iueeeizPPPDN69uwZK6ywQtSEQqEQ06ZNi8aN/S8FxfTxxx9n/+/PO++8ccYZZ0T37t2zX64eeuihOPDAA+Pdd9+tkedNnz9NmzatkWMDzEiWAmqKLAXUB7IUUFNkKWoLV/wxx22wwQax4IILxqmnnvq7+91+++2x7LLLZjMjOnfuHGedddbv7j9kyJB44oknstkT6YM0hak0s+Lvf/97PP/889GtW7fSfadPnx5HHnlktG3bNhvLCSecUO4DOs3yeu2110q3jR8/Ptv2v//9L7uf/kz3//vf/0avXr2yMT711FNZu4aDDz54lscGatYBBxyQ/b/5wgsvxPbbbx9LLLFE9jly2GGHZb9slRg3blxsu+222QzM9Nlwzz33lD521VVXZQHt92Z/pv+v02fMZZddFl26dMl+cUzSPmnbrI4NUB1kKaCmyFJAfSBLATVFlqK2UPhjjmvUqFEMHDgwzjvvvPj8888r3Ofll1+OHXfcMf72t7/FG2+8kX2Y9e/fP/vgm5Xrr78+C29pBtWMmjRpEi1btiy9f/XVV2f3U/BKLRhOPPHEeOSRRyr9Wo4++uisPcQ777wTPXr0qNZjA5Xz7bffxoMPPpj9glX2//cSZUPTgAEDss+Y119/PTbbbLPYeeeds++vjFGjRmW/CN5xxx3lfiGrjmMD/B5ZCqgJshRQX8hSQE2QpahNFP4oijTrIM1KOP744yt8fPDgwbH++utnoSrNjEg92Pv27ZtdIj0r77//fiy11FKz9fwpDKXnTrMedt1111hppZWq1Gc5hacNN9wwFltssWwmVXUeG4hKB57U3mR2PgfSZ8pOO+0Uiy++ePYL348//pjNxqpsG4Vrrrkm+6Wu5Bes6jo2wB+RpYDqJksB9YksBVQ3WYraROGPokn91NMspDQraUZpW+qHXFa6n0JU6llekfTBOrvKfhgmHTp0iLFjx0ZlpfBUU8cGKqeqnwFpFlZad6Gy/5926tQp5p9//ho5NsDskKWA6iRLAfWNLAVUJ1mK2kThj6JZe+21s0WPjznmmGo5XpqBNbsLpKYWC2Wl/sepv3rSsGHDmT6s0yKsFanosu3fOzZQc9JsxvT/2+x8DvzRZ8CMYa2iz4CK/v//o2MDVCdZCqhOshRQ38hSQHWSpahNFP4oqtSH/N57741nn3223Pall146nn766XLb0v0UolIv9oqkxZKHDRsWr7766kyPpQ/HiRMnztaYSmZKjB49unRb2T7JQO2U2pqkX9ouuOCCCv9/T4uhz+5nwA8//FDuGD4DgNpKlgKqiywF1EeyFFBdZClqE4U/iqp79+7ZAqPnnntuue3/+te/sv7jJ510Urz33ntZ64Xzzz8/Dj/88Fkeq1+/flnbhdSDPX3AjhgxIj788MO45ZZbYtVVV83aMcyO5s2bZ/uXLI78+OOPx3/+858//VqBmpf+309tV1ZZZZVsgeP0/336/zh9xqy22mqzdYzevXtHixYt4t///nd88MEHccMNN/zuAu4AxSRLAdVJlgLqG1kKqE6yFLWFwh9FlxYinvFy4xVXXDELRjfddFMst9xycdxxx2X7pcVJZ6VZs2bxyCOPxJFHHhmXXHJJFpJWXnnl7IP14IMPzo4zu6644oqYOnVq9OrVKwtuJ5988p96jcCc0bVr13jllVdi3XXXzX5RS//fp4XO0y9sF1100WzP0LruuuvigQceyH4JvPHGG+OEE06o8bEDVJUsBVQXWQqoj2QpoLrIUtQWDQqVWXUSAAAAAAAAqJVc8QcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwB9Qbu+++e2yzzTal99dZZ53o16/fHB/H//73v2jQoEGMHz9+jj83AEBVyVIAAFUnSwFzisIfUCuCTwoc6da0adNYfPHF48QTT4ypU6fW6PPecccdcdJJJ83WvkIRAFBbyVIAAFUnSwF507jYAwBINtlkk7jyyivjl19+iQceeCAOPPDAaNKkSRxzzDHl9ps8eXIWwqpD27Ztq+U4AADFJksBAFSdLAXkiSv+gFqhWbNmseCCC0anTp1i//33jw022CDuueee0jYIp5xySiy00EKx5JJLZvt/9tlnseOOO8a8886bBaWtt946Pv7449LjTZs2LQ477LDs8Xbt2sWRRx4ZhUKh3HPO2FIhhbujjjoqFl100Ww8aYbX5Zdfnh133XXXzfZp06ZNNsMqjSuZPn16nHrqqdGlS5do3rx5LL/88nHbbbeVe54UGJdYYons8XScsuMEAKgOshQAQNXJUkCeKPwBtVIKI2kWVTJ8+PAYOXJkPPLII3HffffFlClTYuONN4555pknnnzyyXj66adj7rnnzmZnlXzPWWedFVdddVVcccUV8dRTT8W3334bd9555+8+56677ho33nhjnHvuufHOO+/EJZdckh03Ba7bb7892yeNY/To0XHOOedk91O4uuaaa+Liiy+Ot956Kw499ND4xz/+EY8//nhpENxuu+1iyy23jNdeey322muvOProo2v43QMA6jtZCgCg6mQpoC7T6hOoVdLspxSoHnrooTjooIPi66+/jpYtW8Zll11W2krhuuuuy2Y0pW1pllOS2jGkWVSp5/lGG20UQ4YMydoxpHCTpACUjjkr7733Xtxyyy1ZiEuzupKuXbvO1H6hffv22fOUzMQaOHBgDBs2LFZbbbXS70mBLoWzPn36xEUXXRSLLbZYFviSNDPsjTfeiNNPP72G3kEAoD6TpQAAqk6WAvJA4Q+oFdKMqTSLKc2aSuHp73//e5xwwglZT/Xu3buX658+YsSIGDVqVDazqqyff/45Pvjgg5gwYUI2+6l3796ljzVu3DhWWmmlmdoqlEiznho1apSFotmVxjBp0qTYcMMNy21Ps7t69uyZfZ1maJUdR1ISxgAAqossBQBQdbIUkCcKf0CtkHqMp1lIKUilnukpEJVIM6vK+vHHH6NXr15x/fXXz3Sc+eefv8otHCorjSO5//77Y+GFFy73WOrFDgAwp8hSAABVJ0sBeaLwB9QKKUSlRYtnx4orrhg333xz1t6gVatWFe7ToUOHeP7552PttdfO7k+dOjVefvnl7HsrkmZvpRldqQd6SUuFskpmdqXFmUsss8wyWZD69NNPZzkja+mll84Wgy7rueeem63XCQAwu2QpAICqk6WAPGlY7AEAVNbOO+8c8803X2y99dbZIsofffRR1kP94IMPjs8//zzb55BDDonTTjst7rrrrnj33XfjgAMOiPHjx8/ymJ07d47ddtst9thjj+x7So6Z+qsnnTp1yvq2p9YPqb97mlWVWjocfvjh2cLJV199ddbO4ZVXXonzzjsvu5/st99+8f7778cRRxyRLcB8ww03ZIs7AwAUiywFAFB1shRQ2yn8AXVOixYt4oknnoiOHTtmiySn2Ut77rln1ku9ZKbVv/71r9hll12y0JR6l6cwtO222/7ucVNLhx122CELY0sttVTsvffeMXHixOyx1DJhwIABcfTRR8cCCywQffv2zbafdNJJ0b9//zj11FOzcWyyySZZi4UuXbpkj6cx3n777VloW3755bPFnNPCywAAxSJLAQBUnSwF1HYNCrNaURQAAAAAAACoM1zxBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAOaDwBwAAAAAAADmg8AcAAAAAAAA5oPAHAAAAAAAAUff9H6N49U9K70oQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix visualization\n",
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "models = ['Logistic Regression', 'Random Forest', 'ANN']\n",
    "cms = [cm_lr, cm_rf, cm_nn]\n",
    "for ax, cm, title in zip(axes, cms, models):\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        cbar=False,\n",
    "        ax=ax,\n",
    "        xticklabels=['No Churn', 'Churn'],\n",
    "        yticklabels=['No Churn', 'Churn']\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
